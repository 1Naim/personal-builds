From 08e5326b1d405a269e8ab8c1912271e769e03c5a Mon Sep 17 00:00:00 2001
From: Andrea Righi <righi.andrea@gmail.com>
Date: Sun, 14 Jul 2024 11:48:16 +0200
Subject: [PATCH 1/3] scx_bpfland: always refresh task vruntime

Make sure the vruntime of a task is periodically refreshed, also when
the task is directly dispatched on a per-CPU DSQ.

Signed-off-by: Andrea Righi <righi.andrea@gmail.com>
---
 scheds/rust/scx_bpfland/src/bpf/main.bpf.c | 8 +++++++-
 1 file changed, 7 insertions(+), 1 deletion(-)

diff --git a/scheds/rust/scx_bpfland/src/bpf/main.bpf.c b/scheds/rust/scx_bpfland/src/bpf/main.bpf.c
index af3c3d5..3c3f35d 100644
--- a/scheds/rust/scx_bpfland/src/bpf/main.bpf.c
+++ b/scheds/rust/scx_bpfland/src/bpf/main.bpf.c
@@ -262,8 +262,14 @@ static inline u64 task_vtime(struct task_struct *p)
 	 * Limit the vruntime to (vtime_now - slice_ns_lag) to avoid penalizing
 	 * tasks too much (this helps to speed up new fork'ed tasks).
 	 */
-	if (vtime_before(vtime, vtime_now - slice_ns_lag))
+	if (vtime_before(vtime, vtime_now - slice_ns_lag)) {
 		vtime = vtime_now - slice_ns_lag;
+		/*
+		 * Make sure to update the minimum task vruntime, even if we
+		 * don't dispatch the task.
+		 */
+		p->scx.dsq_vtime = vtime;
+	}
 
 	return vtime;
 }
-- 
2.45.2


From 52de4bb4097c19f26a480bd9fbf380bddb569e5d Mon Sep 17 00:00:00 2001
From: Andrea Righi <righi.andrea@gmail.com>
Date: Sun, 14 Jul 2024 11:53:37 +0200
Subject: [PATCH 2/3] scx_bpfland: improve task time slice evaluation

Always assign the maximum time slice if there are idle CPUs in the
system.

Otherwise, double the task's unused time slice to reward tasks that use
less CPU time and at the same time refill the time slice of the tasks
every time they're dispatched.

Signed-off-by: Andrea Righi <righi.andrea@gmail.com>
---
 scheds/rust/scx_bpfland/src/bpf/main.bpf.c | 29 ++++++++++++++++++++--
 1 file changed, 27 insertions(+), 2 deletions(-)

diff --git a/scheds/rust/scx_bpfland/src/bpf/main.bpf.c b/scheds/rust/scx_bpfland/src/bpf/main.bpf.c
index 3c3f35d..b9aea2c 100644
--- a/scheds/rust/scx_bpfland/src/bpf/main.bpf.c
+++ b/scheds/rust/scx_bpfland/src/bpf/main.bpf.c
@@ -274,13 +274,38 @@ static inline u64 task_vtime(struct task_struct *p)
 	return vtime;
 }
 
+/*
+ * Return true if all the CPUs in the system are idle, false otherwise.
+ */
+static bool is_system_busy(void)
+{
+	const struct cpumask *idle_cpumask;
+	bool is_busy;
+
+	idle_cpumask = scx_bpf_get_idle_cpumask();
+	is_busy = bpf_cpumask_empty(idle_cpumask);
+	scx_bpf_put_cpumask(idle_cpumask);
+
+	return is_busy;
+}
+
 /*
  * Return the task's unused portion of its previously assigned time slice in
- * the range a [slice_ns_min..slice_ns].
+ * the range a [slice_ns_min .. slice_ns].
  */
 static inline u64 task_slice(struct task_struct *p)
 {
-	return CLAMP((p->scx.slice + slice_ns_min) / 2, slice_ns_min, slice_ns);
+	/*
+	 * Always return maximum time slice there are idle CPUs in the system.
+	 */
+	if (!is_system_busy())
+		return slice_ns;
+	/*
+	 * Double the amount of unused task slice: this allows to reward tasks
+	 * that use less CPU time and periodically refill the time slice every
+	 * time a task is dispatched.
+	 */
+	return CLAMP(p->scx.slice * 2, slice_ns_min, slice_ns);
 }
 
 /*
-- 
2.45.2


From b19b9ac18cc80be5540ba0c251889b79dd1621f2 Mon Sep 17 00:00:00 2001
From: Andrea Righi <righi.andrea@gmail.com>
Date: Sat, 13 Jul 2024 14:25:25 +0200
Subject: [PATCH 3/3] scx_bpfland: prevent flood of "interactive" tasks

Implement a generic safeguard mechanism to avoid generating too many
interactive tasks in the system, which could nullify the effect of the
interactive/regular task classification.

The safeguard mechanism works by pausing the promotion of new tasks to
interactive if the amount of interactive tasks in the priority queue
exceeds a certain threshold (4x the number of online CPUs).

Stopping the promotion of additional interactive tasks allows to
prioritize those already classified as interactive, thereby preventing
potential "bursts" of excessive interactive tasks.

Halting the promotion of additional interactive tasks allows to
prioritize those already classified as interactive, thereby preventing
potential "bursts" of excessive interactive tasks in the system.

This improves the mitigation provided by commit 640bd562 ("scx_bpfland:
prevent tasks from abusing interactive priority boost") to be more
generic.

Fixes: 640bd562 ("scx_bpfland: prevent tasks from abusing interactive priority boost")
Signed-off-by: Andrea Righi <righi.andrea@gmail.com>
---
 scheds/rust/scx_bpfland/src/bpf/main.bpf.c | 55 +++++++++++++---------
 1 file changed, 34 insertions(+), 21 deletions(-)

diff --git a/scheds/rust/scx_bpfland/src/bpf/main.bpf.c b/scheds/rust/scx_bpfland/src/bpf/main.bpf.c
index b9aea2c..588490c 100644
--- a/scheds/rust/scx_bpfland/src/bpf/main.bpf.c
+++ b/scheds/rust/scx_bpfland/src/bpf/main.bpf.c
@@ -180,15 +180,6 @@ static inline bool is_kthread(const struct task_struct *p)
 	return !!(p->flags & PF_KTHREAD);
 }
 
-/*
- * Return true if the system is capable of accepting more interactive tasks,
- * false otherwise.
- */
-static bool is_interactive_avail(void)
-{
-	return scx_bpf_dsq_nr_queued(PRIO_DSQ) < nr_online_cpus * 4;
-}
-
 /*
  * Access a cpumask in read-only mode (typically to check bits).
  */
@@ -289,6 +280,14 @@ static bool is_system_busy(void)
 	return is_busy;
 }
 
+/*
+ * Return true if priority DSQ is congested, false otherwise.
+ */
+static bool is_prio_congested(void)
+{
+	return scx_bpf_dsq_nr_queued(PRIO_DSQ) > nr_online_cpus * 4;
+}
+
 /*
  * Return the task's unused portion of its previously assigned time slice in
  * the range a [slice_ns_min .. slice_ns].
@@ -454,13 +453,18 @@ static void handle_sync_wakeup(struct task_struct *p)
 	struct task_ctx *tctx;
 
 	/*
-	 * If we are waking up a task set the task as interactive, so that it
-	 * can be dispatched as soon as possible on the first CPU available.
+	 * If we are waking up a task immediately promote it as interactive, so
+	 * that it can be dispatched as soon as possible on the first CPU
+	 * available.
+	 *
+	 * However, if the priority queue is congested, we don't want to
+	 * promote additional interactive tasks, instead we give priority to
+	 * the tasks that are already classified as interactive.
 	 */
 	tctx = lookup_task_ctx(p);
 	if (!tctx)
 		return;
-	if (is_interactive_avail())
+	if (!tctx->is_interactive && !is_prio_congested())
 		tctx->is_interactive = true;
 }
 
@@ -518,7 +522,7 @@ void BPF_STRUCT_OPS(bpfland_enqueue, struct task_struct *p, u64 enq_flags)
 	 * that can consume them) we can just dispatch them to the shared DSQ
 	 * and simply rely on the vruntime logic.
 	 */
-	if (tctx->is_interactive && is_interactive_avail()) {
+	if (tctx->is_interactive) {
 		scx_bpf_dispatch_vtime(p, PRIO_DSQ, slice, vtime, enq_flags);
 		__sync_fetch_and_add(&nr_prio_dispatches, 1);
 	} else {
@@ -739,16 +743,25 @@ void BPF_STRUCT_OPS(bpfland_stopping, struct task_struct *p, bool runnable)
 		 * Classify interactive tasks based on the average amount of their
 		 * voluntary context switches.
 		 *
-		 * A task can be promoted to interactive if the average of
-		 * voluntary context switches per second exceeds nvcsw_thresh.
-		 *
-		 * However, if the average of voluntarily context switches
-		 * drops to zero, the task will be demoted to regular.
+		 * If the average of voluntarily context switches is below
+		 * nvcsw_thresh, the task is classified as regular.
 		 */
-		if (tctx->avg_nvcsw >= nvcsw_thresh)
-			tctx->is_interactive = true;
-		else if (tctx->avg_nvcsw == 0)
+		if (tctx->avg_nvcsw < nvcsw_thresh) {
 			tctx->is_interactive = false;
+			return;
+		}
+		/*
+		 * If the average of voluntarily context switches exceeds
+		 * nvcsw_thresh, the task is classified as interactive, but
+		 * only if the priority queue is not congested (in this case we
+		 * don't want to generate additional interactive tasks in the
+		 * system and we give priority to the tasks that have been
+		 * already classified as interactive).
+		 */
+		if (!is_prio_congested() && tctx->avg_nvcsw >= nvcsw_thresh) {
+			tctx->is_interactive = true;
+			return;
+		}
 	}
 }
 
-- 
2.45.2

